{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to take data using the scope and plot relevant histograms. Will output energy resolution and associated errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pyvisa as visa\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import h5py # This is the python library that creates files/stores data sets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Local scripts\n",
    "import MSO4102Bastro as sdaq # This is the scope module that Sean G. wrote. You will need this module (should be on GitHub, https://github.com/ibrewer/scope-daq)\n",
    "import readData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the IP address of the scope as a string. The IP address of the scope should be set by the router (make sure both the scope and the lab laptop are plugged into the router). To check the IP address of the scope, you can go to the Utility menu and check the LAN settings. Sometimes a LAN reset is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = sdaq.Scope(address=\"169.254.2.185\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output file and data set names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../dataOut/101921_amp1/'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "outName='cobalt57_14h'\n",
    "dsName='run1'\n",
    "#scope.set_source_channel(0) #Set scope channel to read - same as displayed on scope\n",
    "traces=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean run options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlots=True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This command creates a h5py file, desginated as \"f.\" Documentation for h5py can be found at http://docs.h5py.org/en/stable/. \n",
    "### NOTE: Please keep the 'a' flag.  ***Also, make sure you close an open file (use f.close()) before you open a new one.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(path+outName+'.h5py', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an array that stores the scope scaling dictionary. This will make sure that we have the scope settings for any given run.\n",
    "\n",
    "### If you want to extract the scope scaling parameters from a file, the 5 settings are stored in the order [x zero, x incr, y zero, y mult, y offset].\n",
    "### To extract the data, you could say ***data_scale = f['scope_scaling']*** and then extract the values that you want using ***data_scale[1] = x_increment***, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaling_dict = scope.read_scaling_config()\n",
    "\n",
    "scaling_info = np.zeros(5)\n",
    "scaling_info[0] = float(scaling_dict['XZERO'])\n",
    "scaling_info[1] = float(scaling_dict['XINCR'])\n",
    "scaling_info[2] = float(scaling_dict['YZERO'])\n",
    "scaling_info[3] = float(scaling_dict['YMULT'])\n",
    "scaling_info[4] = float(scaling_dict['YOFF'])\n",
    "\n",
    "#AMANDA - debug error with same dataset name from hardcoded \"scope_scaling\"\n",
    "dset = f.create_dataset(dsName+'_scaling', data=scaling_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually take data. Function inputs:\n",
    "1) Length of run [minutes]\n",
    "\n",
    "2) Name of dataset saved\n",
    "\n",
    "3) Number of full traces saved (optional)\n",
    "\n",
    "4) Noise range of points on trace (optional)\n",
    "\n",
    "5) Signal range of points on scope (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scope' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/m4_979p905g801lrswmfm6ww0000gp/T/ipykernel_6215/4234461535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreadData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/AstroPix/analogreadoutanalysis/readData.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(run_time, data_set_name, no_of_traces, noise_range, signal_range)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Determines number of points from each scope trace and creates an empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_triggered_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mlast_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scope' is not defined"
     ]
    }
   ],
   "source": [
    "readData.get_data(14*60, dsName, traces) # take data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the data sets within a file (check to make sure your run is there):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis/plotting: assign the data set as the array \"plot_array.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_array = f[dsName] # insert desired data set name here\n",
    "time_axis = np.array(f[dsName+\"_t\"])\n",
    "#sanity check\n",
    "if len(plot_array)!=traces: \n",
    "    print(\"ERROR - SOMETHING AWRY \\n dataset length is not what was input - are you looking at the right dataset?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 10% of all traces to look at the data and perform a common sense check. Also look for a stretch of data that can be used to determine noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(int(traces*0.1)):\n",
    "    plt.plot(time_axis*1e6, plot_array[i])\n",
    "    \n",
    "plt.xlabel('time [us]')\n",
    "plt.ylabel('peak amplitude [V]')\n",
    "\n",
    "if savePlots:\n",
    "    plt.savefig(path+outName+'_'+dsName+'_traces.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will extract the peak from each trace/row of the data set. The noise sample is determined by eye; pick a range of x values where there don't appear to be (many) peaks, ex. from 2000:3500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peaks = f[dsName + '_peaks' ]\n",
    "integ = f[dsName + \"_integral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a histogram of the peaks using matplotlib to get a sense of what the data looks like and where the peak is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ultra fine binning for debugging input\n",
    "plt.hist(peaks, bins=180)\n",
    "plt.xlabel('peak amplitude [V]')\n",
    "plt.ylabel('counts')\n",
    "\n",
    "if savePlots:\n",
    "    plt.savefig(path+outName+'_'+dsName+'_runtimePeakHist.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same for the trace integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ultra fine binning for debugging input\n",
    "plt.hist(integ, bins=180)\n",
    "plt.xlabel('trace integral [V]')\n",
    "plt.ylabel('counts')\n",
    "\n",
    "if savePlots:\n",
    "    plt.savefig(path+outName+'_'+dsName+'_runtimeIntegHist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are done working with a file, ***make sure you close it!*** h5py does not like it when files are left open and you change files and/or kill the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOU DID IT!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
